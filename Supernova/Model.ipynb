{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Generating Synthetic Supernova Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to generate synthetic supernova data\n",
    "def generate_synthetic_supernova_data(num_samples=1000, img_size=64):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Create \"supernova\" images with a white circle in the center\n",
    "        img_supernova = np.zeros((img_size, img_size), dtype=np.uint8 )\n",
    "        cv2.circle(img_supernova, (img_size//2, img_size//2), 5, (255), -1)  # Bright spot in center\n",
    "        X.append(img_supernova)\n",
    "        y.append(1)  # Label 1 for supernova\n",
    "\n",
    "        # Create \"no supernova\" images (random noise)\n",
    "        img_no_supernova = np.random.randint(0, 255, (img_size, img_size), dtype=np.uint8)\n",
    "        X.append(img_no_supernova)\n",
    "        y.append(0)  # Label 0 for no supernova\n",
    "\n",
    "    X = np.array(X).reshape(-1, img_size, img_size, 1) / 255.0  # Normalize\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = generate_synthetic_supernova_data(num_samples=1000)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2. Model Architecture: Convolutional Neural Network (CNN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9293 - loss: 0.1898 - val_accuracy: 1.0000 - val_loss: 6.6000e-08\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.0621e-08 - val_accuracy: 1.0000 - val_loss: 2.2297e-08\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.2054e-08 - val_accuracy: 1.0000 - val_loss: 2.1746e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.4956e-08 - val_accuracy: 1.0000 - val_loss: 2.1667e-08\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.3088e-08 - val_accuracy: 1.0000 - val_loss: 2.1590e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.2409e-08 - val_accuracy: 1.0000 - val_loss: 2.1509e-08\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0290e-08 - val_accuracy: 1.0000 - val_loss: 2.1421e-08\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0611e-08 - val_accuracy: 1.0000 - val_loss: 2.1327e-08\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.2360e-08 - val_accuracy: 1.0000 - val_loss: 2.1234e-08\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.0625e-08 - val_accuracy: 1.0000 - val_loss: 2.1140e-08\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.1975e-08 - val_accuracy: 1.0000 - val_loss: 2.1044e-08\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.1977e-08 - val_accuracy: 1.0000 - val_loss: 2.0947e-08\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.1664e-08 - val_accuracy: 1.0000 - val_loss: 2.0849e-08\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.9701e-08 - val_accuracy: 1.0000 - val_loss: 2.0749e-08\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.2823e-08 - val_accuracy: 1.0000 - val_loss: 2.0652e-08\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.2901e-08 - val_accuracy: 1.0000 - val_loss: 2.0555e-08\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.1683e-08 - val_accuracy: 1.0000 - val_loss: 2.0456e-08\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.0065e-08 - val_accuracy: 1.0000 - val_loss: 2.0361e-08\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.0957e-08 - val_accuracy: 1.0000 - val_loss: 2.0261e-08\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.9251e-08 - val_accuracy: 1.0000 - val_loss: 2.0165e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n",
      "Model saved as 'supernova_detector.h5'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate more robust synthetic data\n",
    "def generate_data(num_samples=1000, img_size=64):\n",
    "    X, y = [], []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Supernova images with noise\n",
    "        img_supernova = np.random.randint(0, 50, (img_size, img_size), dtype=np.uint8)\n",
    "        cv2.circle(img_supernova, (img_size//2, img_size//2), np.random.randint(5, 10), (255), -1)\n",
    "        X.append(img_supernova)\n",
    "        y.append(1)\n",
    "\n",
    "        # No supernova images\n",
    "        img_no_supernova = np.random.randint(0, 255, (img_size, img_size), dtype=np.uint8)\n",
    "        X.append(img_no_supernova)\n",
    "        y.append(0)\n",
    "\n",
    "    X = np.array(X).reshape(-1, img_size, img_size, 1) / 255.0\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "# Generate data\n",
    "X, y = generate_data(num_samples=1000)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# 4. Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 5. Save the Model\n",
    "model.save('supernova_detector.h5')\n",
    "print(\"Model saved as 'supernova_detector.h5'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5. Classifying Uploaded Images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload an image to classify:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbfe92627a549ac9ca0a9065e68b8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load the trained model \n",
    "try:\n",
    "    model = tf.keras.models.load_model('supernova_detector.h5')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Model file 'supernova_detector.h5' not found.\")\n",
    "    raise\n",
    "\n",
    "# Function to preprocess the uploaded image\n",
    "# Function to preprocess the uploaded image\n",
    "def preprocess_image(uploaded_image):\n",
    "    try:\n",
    "        # Open the image and convert it to grayscale\n",
    "        img = Image.open(uploaded_image).convert('L')  # Convert to grayscale\n",
    "        img = img.resize((64, 64))  # Resize to match model input\n",
    "        img = np.array(img) / 255.0  # Normalize pixel values\n",
    "        img = np.expand_dims(img, axis=(0, -1))  # Add batch and channel dimensions\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the image: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Function to classify the uploaded image with debugging\n",
    "def classify_image(change):\n",
    "    try:\n",
    "        # Clear previous output\n",
    "        clear_output(wait=True)\n",
    "        display(uploader)  # Re-display the uploader widget\n",
    "        \n",
    "        # Check if a file was uploaded\n",
    "        if not change['new']:\n",
    "            print(\"No file uploaded.\")\n",
    "            return\n",
    "\n",
    "        # Get the uploaded file content\n",
    "        uploaded_file = change['new'][0]\n",
    "        img_data = uploaded_file['content']\n",
    "        \n",
    "        # Preprocess the image\n",
    "        # Debugging the preprocessing step\n",
    "        img = preprocess_image(io.BytesIO(img_data))\n",
    "        print(\"Processed Image Shape:\", img.shape)\n",
    "        print(\"Processed Image Pixel Range:\", img.min(), img.max())\n",
    "\n",
    "        # Visualize the processed image\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(img[0, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Uploaded Image After Preprocessing\")\n",
    "        plt.show()\n",
    "\n",
    "        # Predict the class\n",
    "        prediction = model.predict(img)[0][0]\n",
    "        print(f\"Raw Prediction: {prediction:.4f}\")  # Display raw prediction\n",
    "        \n",
    "        # Classify based on threshold\n",
    "        threshold = 0.4  # Adjust based on observed raw predictions\n",
    "        result = \"Supernova Detected\" if prediction > threshold else \"No Supernova Detected\"\n",
    "\n",
    "        print(f\"Result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Create the upload widget\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='image/*',  # Accept image files\n",
    "    multiple=False  # Single file upload\n",
    ")\n",
    "\n",
    "# Attach the event handler\n",
    "uploader.observe(classify_image, names='value')\n",
    "\n",
    "# Display the uploader widget\n",
    "print(\"Upload an image to classify:\")\n",
    "display(uploader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
